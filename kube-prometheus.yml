# exporter-node configuration
deployExporterNode: True

# Grafana
deployGrafana: True

## If true, create & use RBAC resources resp. Pod Security Policies
##
global:
  rbacEnable: true
  pspEnable: true

# AlertManager
deployAlertManager: False

alertmanager:
  ## Alertmanager configuration directives
  ## Ref: https://prometheus.io/docs/alerting/configuration/
  ##
  config:
    global:
      resolve_timeout: 5m
    route:
      group_by: ['job']
      group_wait: 30s
      group_interval: 5m
      repeat_interval: 12h
      receiver: 'null'
      routes:
      - match:
          alertname: DeadMansSwitch
        receiver: 'null'
    receivers:
    - name: 'null'

  ## External URL at which Alertmanager will be reachable
  ##
  externalUrl: ""

  ## Alertmanager container image
  ##
  image:
    repository: quay.io/prometheus/alertmanager
    tag: v0.14.0

  ingress:
    ## If true, Alertmanager Ingress will be created
    ##
    enabled: false

    ## Annotations for Alertmanager Ingress
    ##
    annotations: {}
      # kubernetes.io/ingress.class: nginx
      # kubernetes.io/tls-acme: "true"

    ## Labels to be added to the Ingress
    ##
    labels: {}

    ## Hostnames.
    ## Must be provided if Ingress is enabled.
    ##
    # hosts:
    #   - alertmanager.domain.com
    hosts: []

    ## TLS configuration for Alertmanager Ingress
    ## Secret must be manually created in the namespace
    ##
    tls: []
      # - secretName: alertmanager-general-tls
      #   hosts:
      #     - alertmanager.example.com

  ## Node labels for Alertmanager pod assignment
  ## Ref: https://kubernetes.io/docs/user-guide/node-selection/
  ##
  nodeSelector: {}

  ## If true, the Operator won't process any Alertmanager configuration changes
  ##
  paused: false

  ## Number of Alertmanager replicas desired
  ##
  replicaCount: 1

  ## Pod anti-affinity can prevent the scheduler from placing Alertmanager replicas on the same node.
  ## The default value "soft" means that the scheduler should *prefer* to not schedule two replica pods onto the same node but no guarantee is provided.
  ## The value "hard" means that the scheduler is *required* to not schedule two replica pods onto the same node.
  ## The value "" will disable pod anti-affinity so that no anti-affinity rules will be configured.
  podAntiAffinity: "soft"

  ## Resource limits & requests
  ## Ref: https://kubernetes.io/docs/user-guide/compute-resources/
  ##
  resources: {}
    # requests:
    #   memory: 400Mi

  ## List of Secrets in the same namespace as the AlertManager
  ## object, which shall be mounted into the AlertManager Pods.
  ## Ref: https://github.com/coreos/prometheus-operator/blob/master/Documentation/api.md#alertmanagerspec
  ##
  secrets: []

  service:
    ## Annotations to be added to the Service
    ##
    annotations: {}

    ## Cluster-internal IP address for Alertmanager Service
    ##
    clusterIP: ""

    ## List of external IP addresses at which the Alertmanager Service will be available
    ##
    externalIPs: []

    ## External IP address to assign to Alertmanager Service
    ## Only used if service.type is 'LoadBalancer' and supported by cloud provider
    ##
    loadBalancerIP: ""

    ## List of client IPs allowed to access Alertmanager Service
    ## Only used if service.type is 'LoadBalancer' and supported by cloud provider
    ##
    loadBalancerSourceRanges: []

    ## Port to expose on each node
    ## Only used if service.type is 'NodePort'
    ##
    nodePort: 30903

    ## Service type
    ##
    type: ClusterIP

  ## Alertmanager StorageSpec for persistent data
  ## Ref: https://github.com/coreos/prometheus-operator/blob/master/Documentation/user-guides/storage.md
  ##
  storageSpec: {}
  #  volumeClaimTemplate:
  #    spec:
  #      storageClassName: gluster
  #      accessModes: ["ReadWriteOnce"]
  #      resources:
  #        requests:
  #          storage: 50Gi
  #    selector: {}

prometheus:
  ## Alertmanagers to which alerts will be sent
  ## Ref: https://github.com/coreos/prometheus-operator/blob/master/Documentation/api.md#alertmanagerendpoints
  ##
  alertingEndpoints: []
  #   - name: ""
  #     namespace: ""
  #     port: 9093
  #     scheme: http

  ## Prometheus configuration directives
  ## Ignored if serviceMonitors are defined
  ## Ref: https://prometheus.io/docs/operating/configuration/
  ##
  config:
    specifiedInValues: true
    value: {}

  ## External URL at which Prometheus will be reachable
  ##
  externalUrl: ""

  ## Prometheus container image
  ##
  image:
    repository: quay.io/prometheus/prometheus
    tag: v2.2.1

  ingress:
    ## If true, Prometheus Ingress will be created
    ##
    enabled: false

    ## Annotations for Prometheus Ingress
    ##
    annotations: {}
      # kubernetes.io/ingress.class: nginx
      # kubernetes.io/tls-acme: "true"

    ## Labels to be added to the Ingress
    ##
    labels: {}

    ## Hostnames.
    ## Must be provided if Ingress is enabled.
    ##
    # hosts:
    #   - alertmanager.domain.com
    hosts: []

    ## TLS configuration for Prometheus Ingress
    ## Secret must be manually created in the namespace
    ##
    tls: []
      # - secretName: prometheus-k8s-tls
      #   hosts:
      #     - prometheus.example.com

  ## Node labels for Prometheus pod assignment
  ## Ref: https://kubernetes.io/docs/user-guide/node-selection/
  ##
  nodeSelector: {}

  ## If true, the Operator won't process any Prometheus configuration changes
  ##
  paused: false

  ## Number of Prometheus replicas desired
  ##
  replicaCount: 1

  ## Pod anti-affinity can prevent the scheduler from placing Prometheus replicas on the same node.
  ## The default value "soft" means that the scheduler should *prefer* to not schedule two replica pods onto the same node but no guarantee is provided.
  ## The value "hard" means that the scheduler is *required* to not schedule two replica pods onto the same node.
  ## The value "" will disable pod anti-affinity so that no anti-affinity rules will be configured.
  podAntiAffinity: "soft"

  ## Resource limits & requests
  ## Ref: https://kubernetes.io/docs/user-guide/compute-resources/
  ##
  resources: {}
    # requests:
    #   memory: 400Mi

  ## List of Secrets in the same namespace as the Prometheus
  ## object, which shall be mounted into the Prometheus Pods.
  ## Ref: https://github.com/coreos/prometheus-operator/blob/master/Documentation/api.md#prometheusspec
  ##
  secrets: []

  ## How long to retain metrics
  ##
  retention: 24h

  ## Prefix used to register routes, overriding externalUrl route.
  ## Useful for proxies that rewrite URLs.
  ##
  routePrefix: /

  ## Rules configmap selector
  ## Ref: https://github.com/coreos/prometheus-operator/blob/master/Documentation/design.md
  ##
  ## 1. If `matchLabels` is used, `rules.additionalLabels` must contain all the labels from
  ##    `matchLabels` in order to be be matched by Prometheus
  ## 2. If `matchExpressions` is used `rules.additionalLabels` must contain at least one label
  ##    from `matchExpressions` in order to be matched by Prometheus
  ## Ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels
  rulesSelector: {}
   # rulesSelector: {
   #   matchExpressions: [{key: prometheus, operator: In, values: [example-rules, example-rules-2]}]
   # }
   ### OR
   # rulesSelector: {
   #   matchLabels: [{role: example-rules}]
   # }

  ## Prometheus alerting & recording rules
  ## Ref: https://prometheus.io/docs/querying/rules/
  ## Ref: https://prometheus.io/docs/alerting/rules/
  ##
  rules:
    specifiedInValues: true
    ## What additional rules to be added to the ConfigMap
    ## You can use this together with `rulesSelector`
    additionalLabels: {}
    #  prometheus: example-rules
    #  application: etcd
    value: {}

  service:
    ## Annotations to be added to the Service
    ##
    annotations: {}

    ## Cluster-internal IP address for Prometheus Service
    ##
    clusterIP: ""

    ## List of external IP addresses at which the Prometheus Service will be available
    ##
    externalIPs: []

    ## External IP address to assign to Prometheus Service
    ## Only used if service.type is 'LoadBalancer' and supported by cloud provider
    ##
    loadBalancerIP: ""

    ## List of client IPs allowed to access Prometheus Service
    ## Only used if service.type is 'LoadBalancer' and supported by cloud provider
    ##
    loadBalancerSourceRanges: []

    ## Port to expose on each node
    ## Only used if service.type is 'NodePort'
    ##
    nodePort: 30900

    ## Service type
    ##
    type: NodePort

  ## Service monitors selector
  ## Ref: https://github.com/coreos/prometheus-operator/blob/master/Documentation/design.md
  ##
  serviceMonitorsSelector:
    matchExpressions:
    - key: app
      operator: In
      values:
      - alertmanager
      - exporter-coredns
      - exporter-kube-controller-manager
      - exporter-kube-dns
      - exporter-kube-etcd
      - exporter-kube-scheduler
      - exporter-kube-state
      - exporter-kubelets
      - exporter-kubernetes
      - exporter-node
      - grafana
      - prometheus
      - prometheus-operator

  ## ServiceMonitor CRDs to create & be scraped by the Prometheus instance.
  ## Ref: https://github.com/coreos/prometheus-operator/blob/master/Documentation/service-monitor.md
  ##
  serviceMonitors: []
    ## Name of the ServiceMonitor to create
    ##
    # - name: ""

      ## Service label for use in assembling a job name of the form <label value>-<port>
      ## If no label is specified, the service name is used.
      ##
      # jobLabel: ""

      ## Label selector for services to which this ServiceMonitor applies
      ##
      # selector: {}

      ## Namespaces from which services are selected
      ##
      # namespaceSelector:
        ## Match any namespace
        ##
        # any: false

        ## Explicit list of namespace names to select
        ##
        # matchNames: []

      ## Endpoints of the selected service to be monitored
      ##
      # endpoints: []
        ## Name of the endpoint's service port
        ## Mutually exclusive with targetPort
        # - port: ""

        ## Name or number of the endpoint's target port
        ## Mutually exclusive with port
        # - targetPort: ""

        ## File containing bearer token to be used when scraping targets
        ##
        #   bearerTokenFile: ""

        ## Interval at which metrics should be scraped
        ##
        #   interval: 30s

        ## HTTP path to scrape for metrics
        ##
        #   path: /metrics

        ## HTTP scheme to use for scraping
        ##
        #   scheme: http

        ## TLS configuration to use when scraping the endpoint
        ##
        #   tlsConfig:

            ## Path to the CA file
            ##
            # caFile: ""

            ## Path to client certificate file
            ##
            # certFile: ""

            ## Skip certificate verification
            ##
            # insecureSkipVerify: false

            ## Path to client key file
            ##
            # keyFile: ""

            ## Server name used to verify host name
            ##
            # serverName: ""

  ## Prometheus StorageSpec for persistent data
  ## Ref: https://github.com/coreos/prometheus-operator/blob/master/Documentation/user-guides/storage.md
  ##
  storageSpec: {}
  #  volumeClaimTemplate:
  #    spec:
  #      storageClassName: gluster
  #      accessModes: ["ReadWriteOnce"]
  #      resources:
  #        requests:
  #          storage: 50Gi
  #    selector: {}
  additionalScrapeConfigs:
    - job_name: "prediction"
      scrape_interval: 15s
      static_configs:
      - targets:
        - "predicted-cpu-exporter:9999"

# default rules are in templates/general.rules.yaml
# prometheusRules: {}

# Select Deployed DNS Solution
deployCoreDNS: false
deployKubeDNS: true


grafana:
  nodeSelector: {}
  
  ## Tolerations for use with node taints
  ## Ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
  ##
  tolerations: {}
    #  - key: "key"
    #    operator: "Equal"
    #    value: "value"
    #    effect: "NoSchedule"
  
  annotations: {}
  
  ## If true, create a serviceMonitor for grafana
  ##
  selfServiceMonitor: true
  ## Custom Labels to be added to ServiceMonitor
  ##
  additionalServiceMonitorLabels: {}
  
  ## If true, create & use RBAC resources resp. Pod Security Policies
  ##
  global:
    rbacEnable: true
    pspEnable: true
  
  ## Pass extra environment variables to the Grafana container.
  ##
  # extraVars:
  # - name: EXTRA_VAR_1
  #   value: extra-var-value-1
  # - name: EXTRA_VAR_2
  #   value: extra-var-value-2
  extraVars:
  
  ## Change to true override Grafana's default config.
  ## Make sure grafana.ini is present on /etc/grafana
  mountGrafanaConfig: false
  
  adminUser: "admin"
  adminPassword: "admin"
  
  service:
  
    ## Annotations to be added to the Service
    ##
    annotations: {}
  
    ## Cluster-internal IP address for Alertmanager Service
    ##
    clusterIP: ""
  
    ## List of external IP addresses at which the Alertmanager Service will be available
    ##
    externalIPs: []
  
    ## External IP address to assign to Alertmanager Service
    ## Only used if service.type is 'LoadBalancer' and supported by cloud provider
    ##
    loadBalancerIP: ""
  
    ## List of client IPs allowed to access Alertmanager Service
    ## Only used if service.type is 'LoadBalancer' and supported by cloud provider
    ##
    loadBalancerSourceRanges: []
  
    ## Port to expose on each node
    ## Only used if service.type is 'NodePort'
    ##
    nodePort: 30902
  
    ## Service type
    ##
    type: NodePort
  
  ## Grafana Docker image
  ##
  image:
    repository: grafana/grafana
    tag: 5.0.0
  
  grafanaWatcher:
    repository: quay.io/coreos/grafana-watcher
    tag: v0.0.8
  
  storageSpec: {}
  #   class: default
  #   accessMode:
  #   resources:
  #     requests:
  #       storage: 2Gi
  #   selector: {}
  
  resources: {}
    # requests:
    #   memory: 400Mi
  
  ingress:
    ## If true, Grafana Ingress will be created
    ##
    enabled: false
  
    ## Annotations for Alertmanager Ingress
    ##
    annotations: {}
      # kubernetes.io/ingress.class: nginx
      # kubernetes.io/tls-acme: "true"
  
    ## Labels to be added to the Ingress
    ##
    labels: {}
    
    ## Hostnames.
    ## Must be provided if Ingress is enabled.
    ##
    # hosts:
    #   - grafana.domain.com
    hosts: []
  
    ## TLS configuration for Alertmanager Ingress
    ## Secret must be manually created in the namespace
    ##
    tls: []
      # - secretName: alertmanager-general-tls
      #   hosts:
      #     - alertmanager.example.com
  
  
  
  # Set datasource in beginning
  dataSource: {}
  
  ## A list of additional configmaps that contain -dashboard.json and/or -datasource.json files
  ## that should be imported into grafana.
  serverDashboardConfigmaps: []
  
  serverDashboardFiles:
    cpu-dashboard.json: |+
      {
        "dashboard" : {
            "__inputs": [
              {
                "name": "DS_PROMETHEUS",
                "label": "prometheus",
                "description": "",
                "type": "datasource",
                "pluginId": "prometheus",
                "pluginName": "Prometheus"
              }
            ],
            "__requires": [
              {
                "type": "grafana",
                "id": "grafana",
                "name": "Grafana",
                "version": "5.0.0"
              },
              {
                "type": "panel",
                "id": "graph",
                "name": "Graph",
                "version": "5.0.0"
              },
              {
                "type": "datasource",
                "id": "prometheus",
                "name": "Prometheus",
                "version": "5.0.0"
              }
            ],
            "annotations": {
              "list": [
                {
                  "builtIn": 1,
                  "datasource": "-- Grafana --",
                  "enable": true,
                  "hide": true,
                  "iconColor": "rgba(0, 211, 255, 1)",
                  "name": "Annotations & Alerts",
                  "type": "dashboard"
                }
              ]
            },
            "editable": true,
            "gnetId": null,
            "graphTooltip": 1,
            "id": null,
            "iteration": 1528037979222,
            "links": [],
            "panels": [
              {
                "aliasColors": {},
                "bars": false,
                "dashLength": 10,
                "dashes": false,
                "datasource": "${DS_PROMETHEUS}",
                "fill": 1,
                "gridPos": {
                  "h": 9,
                  "w": 24,
                  "x": 0,
                  "y": 0
                },
                "id": 11,
                "legend": {
                  "avg": false,
                  "current": false,
                  "max": false,
                  "min": false,
                  "show": true,
                  "total": false,
                  "values": false
                },
                "lines": true,
                "linewidth": 1,
                "links": [],
                "nullPointMode": "null",
                "percentage": false,
                "pointradius": 5,
                "points": false,
                "renderer": "flot",
                "seriesOverrides": [],
                "spaceLength": 10,
                "stack": false,
                "steppedLine": false,
                "targets": [
                  {
                    "expr": "sum(rate(container_cpu_usage_seconds_total{namespace=\"$deployment_namespace\",pod_name=~\"$deployment_name.*\"}[1m]))*1000",
                    "format": "time_series",
                    "intervalFactor": 2,
                    "legendFormat": "Current CPU utilization",
                    "refId": "A"
                  },
                  {
                    "expr": "prediction_cpu_usage",
                    "format": "time_series",
                    "intervalFactor": 1,
                    "legendFormat": "Predicted CPU utilization",
                    "refId": "D"
                  },
                  {
                    "expr": "sum(kube_pod_container_resource_requests_cpu_cores{namespace=\"$deployment_namespace\", pod=~\"$deployment_name.*\"})*1000",
                    "format": "time_series",
                    "intervalFactor": 1,
                    "legendFormat": "CPU requests",
                    "refId": "C"
                  },
                  {
                    "expr": "sum(kube_pod_container_resource_requests_cpu_cores{namespace=\"$deployment_namespace\", pod=~\"$deployment_name.*\"})*700",
                    "format": "time_series",
                    "intervalFactor": 1,
                    "legendFormat": "Desired CPU utilization",
                    "refId": "E"
                  }
                ],
                "thresholds": [],
                "timeFrom": null,
                "timeShift": null,
                "title": "CPU Usage",
                "tooltip": {
                  "shared": true,
                  "sort": 0,
                  "value_type": "individual"
                },
                "type": "graph",
                "xaxis": {
                  "buckets": null,
                  "mode": "time",
                  "name": null,
                  "show": true,
                  "values": []
                },
                "yaxes": [
                  {
                    "format": "short",
                    "label": "CPU utilization [milicores]",
                    "logBase": 1,
                    "max": null,
                    "min": null,
                    "show": true
                  },
                  {
                    "format": "short",
                    "label": null,
                    "logBase": 1,
                    "max": null,
                    "min": null,
                    "show": true
                  }
                ]
              },
              {
                "aliasColors": {},
                "bars": false,
                "dashLength": 10,
                "dashes": false,
                "datasource": "${DS_PROMETHEUS}",
                "fill": 1,
                "gridPos": {
                  "h": 7,
                  "w": 24,
                  "x": 0,
                  "y": 9
                },
                "id": 13,
                "legend": {
                  "avg": false,
                  "current": false,
                  "max": false,
                  "min": false,
                  "show": true,
                  "total": false,
                  "values": false
                },
                "lines": true,
                "linewidth": 1,
                "links": [],
                "nullPointMode": "null",
                "percentage": false,
                "pointradius": 5,
                "points": false,
                "renderer": "flot",
                "seriesOverrides": [],
                "spaceLength": 10,
                "stack": false,
                "steppedLine": false,
                "targets": [
                  {
                    "expr": "(sum(rate(container_cpu_usage_seconds_total{namespace=\"default\",pod_name=~\"podinfo.*\"}[1m]))) / (sum(kube_pod_container_resource_requests_cpu_cores{namespace=\"default\", pod=~\"podinfo.*\"}))*100",
                    "format": "time_series",
                    "intervalFactor": 1,
                    "legendFormat": "Current CPU utilization",
                    "refId": "A"
                  },
                  {
                    "expr": "prediction_cpu_usage_percent",
                    "format": "time_series",
                    "intervalFactor": 1,
                    "legendFormat": "Predicted CPU utilization",
                    "refId": "B"
                  },
                  {
                    "expr": "100",
                    "format": "time_series",
                    "intervalFactor": 1,
                    "legendFormat": "CPU requests",
                    "refId": "D"
                  },
                  {
                    "expr": "70",
                    "format": "time_series",
                    "intervalFactor": 1,
                    "legendFormat": "Desired CPU utilization",
                    "refId": "C"
                  }
                ],
                "thresholds": [],
                "timeFrom": null,
                "timeShift": null,
                "title": "Panel Title",
                "tooltip": {
                  "shared": true,
                  "sort": 0,
                  "value_type": "individual"
                },
                "type": "graph",
                "xaxis": {
                  "buckets": null,
                  "mode": "time",
                  "name": null,
                  "show": true,
                  "values": []
                },
                "yaxes": [
                  {
                    "format": "short",
                    "label": "CPU utilization [%]",
                    "logBase": 1,
                    "max": null,
                    "min": null,
                    "show": true
                  },
                  {
                    "format": "short",
                    "label": null,
                    "logBase": 1,
                    "max": null,
                    "min": null,
                    "show": true
                  }
                ]
              }
            ],
            "refresh": "30s",
            "schemaVersion": 16,
            "style": "dark",
            "tags": [],
            "templating": {
              "list": [
                {
                  "allValue": ".*",
                  "current": {},
                  "datasource": "${DS_PROMETHEUS}",
                  "hide": 0,
                  "includeAll": false,
                  "label": "Namespace",
                  "multi": false,
                  "name": "deployment_namespace",
                  "options": [],
                  "query": "label_values(kube_deployment_metadata_generation, namespace)",
                  "refresh": 1,
                  "regex": "",
                  "sort": 0,
                  "tagValuesQuery": null,
                  "tags": [],
                  "tagsQuery": "",
                  "type": "query",
                  "useTags": false
                },
                {
                  "allValue": null,
                  "current": {},
                  "datasource": "${DS_PROMETHEUS}",
                  "hide": 0,
                  "includeAll": false,
                  "label": "Deployment",
                  "multi": false,
                  "name": "deployment_name",
                  "options": [],
                  "query": "label_values(kube_deployment_metadata_generation{namespace=\"$deployment_namespace\"}, deployment)",
                  "refresh": 1,
                  "regex": "",
                  "sort": 0,
                  "tagValuesQuery": "",
                  "tags": [],
                  "tagsQuery": "deployment",
                  "type": "query",
                  "useTags": false
                }
              ]
            },
            "time": {
              "from": "now-30m",
              "to": "now"
            },
            "timepicker": {
              "refresh_intervals": [
                "5s",
                "10s",
                "30s",
                "1m",
                "5m",
                "15m",
                "30m",
                "1h",
                "2h",
                "1d"
              ],
              "time_options": [
                "5m",
                "15m",
                "1h",
                "6h",
                "12h",
                "24h",
                "2d",
                "7d",
                "30d"
              ]
            },
            "timezone": "browser",
            "title": "CPU",
            "uid": "PUdDZAnmz",
            "version": 1
          },
        "inputs": [
          {
            "name": "DS_PROMETHEUS",
            "pluginId": "prometheus",
            "type": "datasource",
            "value": "prometheus"
          }
        ],
        "overwrite": true
      }


  ## Keep the Dashboards that are defined in this HELM chart
  keepOriginalDashboards: true
  
  ## Keep the Datasources that are defined in this HELM chart
  keepOriginalDatasources: true
  
  auth:
    anonymous:
      enabled: "true"
